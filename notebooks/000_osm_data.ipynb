{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cel\n",
    "Wyciągnięcie danych na temat dróg i POI w województwie śląskim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from OSMPythonTools.nominatim import Nominatim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting overpass.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile overpass.py\n",
    "\n",
    "import urllib\n",
    "\n",
    "from OSMPythonTools.overpass import Overpass\n",
    "\n",
    "\n",
    "class CustomOverpass(Overpass):\n",
    "    \n",
    "    # make sure it is GET method with properly (from the point of overpass api server) \n",
    "    # escaped query strings\n",
    "    def _queryRequest(self, endpoint, queryString, params=None):\n",
    "        # is the the overpass server broken?\n",
    "        # qstr = urllib.parse.urlencode({'data': queryString, **(params or {})})\n",
    "        qstr = \"&\".join(f\"{k}={v}\" for k, v in {'data': queryString, **(params or {})}.items())\n",
    "        print( endpoint + f\"interpreter?{qstr}\")\n",
    "        return urllib.request.Request(\n",
    "            endpoint + f\"interpreter?{qstr}\", \n",
    "            method=\"GET\"\n",
    "        )\n",
    "    \n",
    "    # add util method for building sample queries\n",
    "    def from_statements(self, statements, **kwargs):\n",
    "        query = (\n",
    "            \"(\" + \n",
    "            \";\".join(statement for statement in statements) +\n",
    "            \";);\" +\n",
    "            \"out+skel+body+meta+geom;\"\n",
    "        )\n",
    "        \n",
    "        return self.query(query, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from overpass import *\n",
    "nominatim = Nominatim()          \n",
    "overpass = CustomOverpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "silesia = nominatim.query(\"województwo śląskie\", params={\"polygon_geojson\": 1}).toJSON()[0]\n",
    "bbox = silesia[\"boundingbox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.5 s, sys: 5.73 s, total: 51.2 s\n",
      "Wall time: 52.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get road segments with all possible tags\n",
    "road_segments = overpass.from_statements(\n",
    "    statements = [\n",
    "        \"way[highway](bbox)\",\n",
    "        \"node(w)\",\n",
    "    ],\n",
    "    params={\"bbox\": \",\".join([bbox[2], bbox[0], bbox[3], bbox[1]])},\n",
    "    timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature(element, coords, shape_type, values_to_ignore=None):\n",
    "    tags = {\n",
    "        k: v\n",
    "        for k, v in element.get(\"tags\", {}).items()\n",
    "        if v not in values_to_ignore\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"type\": \"Feature\",\n",
    "        \"id\": f\"{element['type']}/{element['id']}\",\n",
    "        \"properties\": {\n",
    "            \"id\": f\"{element['type']}/{element['id']}\",\n",
    "            **tags\n",
    "        },\n",
    "        \"geometry\": {\n",
    "            \"type\": shape_type,\n",
    "            \"coordinates\": coords\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def transform_to_geojson(overpass_elements, types=None, values_to_ignore=None, **kwargs):\n",
    "    if not types:\n",
    "        types = []\n",
    "    \n",
    "    nodes = [element for element in overpass_elements if element[\"type\"] == \"node\"]\n",
    "    ways = [element for element in overpass_elements if element[\"type\"] == \"way\"]\n",
    "    relations = [element for element in overpass_elements if element[\"type\"] == \"relation\"]\n",
    "    \n",
    "    return {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": (\n",
    "            ([\n",
    "                build_feature(\n",
    "                    element, \n",
    "                    (element[\"lon\"], element[\"lat\"]),\n",
    "                    shape_type=\"Point\",\n",
    "                    values_to_ignore=to_remove\n",
    "                )\n",
    "                for element in nodes if kwargs.get(\"node_condition\", lambda x: x)(element)\n",
    "            ] if \"nodes\" in types else [])\n",
    "            + ([\n",
    "                build_feature(\n",
    "                    element, \n",
    "                    [(node[\"lon\"], node[\"lat\"]) for node in element[\"geometry\"]],\n",
    "                    shape_type=\"LineString\",\n",
    "                    values_to_ignore=values_to_ignore\n",
    "                )\n",
    "                for element in ways            \n",
    "            ] if \"ways\" in types else [])\n",
    "            + ([\n",
    "                build_feature(\n",
    "                    element, \n",
    "                    [\n",
    "                        tuple([\n",
    "                            (point[\"lon\"], point[\"lat\"]) \n",
    "                            for point in node[\"geometry\"]\n",
    "                        ])\n",
    "                        for node in element[\"members\"]\n",
    "                        if node[\"type\"] == \"way\"\n",
    "                    ],\n",
    "                    shape_type=\"MultiLineString\",\n",
    "                    values_to_ignore=to_remove\n",
    "                )\n",
    "                for element in relations \n",
    "            ] if \"relations\" in types else [])\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "444it [00:20, 21.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 4.02 s, total: 19.3 s\n",
      "Wall time: 20.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def batch_entries(collection, batch_size=10000):\n",
    "    ix = 0\n",
    "\n",
    "    while collection[ix * batch_size: (ix + 1) * batch_size ]:\n",
    "        yield collection[ix * batch_size: (ix + 1) * batch_size]\n",
    "        ix += 1\n",
    "\n",
    "\n",
    "ix = 0\n",
    "for collection in tqdm(batch_entries(road_segments.toJSON()[\"elements\"])):\n",
    "    data = transform_to_geojson(\n",
    "        collection, \n",
    "        types=[\"ways\"],\n",
    "        values_to_ignore=[\"2017-09-31\"]\n",
    "    )\n",
    "    if not data[\"features\"]:\n",
    "        continue\n",
    "    \n",
    "    with open(f\"../output/silesia_{ix:04}.geojson\", \"w\") as f:\n",
    "        f.write(json.dumps(data))\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [04:10<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 51s, sys: 10.7 s, total: 4min 2s\n",
      "Wall time: 4min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shape_gdf = gpd.read_file(json.dumps(silesia))\n",
    "roads_gdfs = []\n",
    "\n",
    "for file in tqdm(sorted(glob.glob(\"../output/silesia*.geojson\"))):\n",
    "    roads_gdfs.append(\n",
    "        gpd.sjoin(\n",
    "            gpd.read_file(file, crs=\"epsg:4326\"), \n",
    "            shape_gdf, \n",
    "            op=\"within\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 s, sys: 2.59 s, total: 39.4 s\n",
      "Wall time: 40.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "roads = pd.concat(roads_gdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 4.11 s, total: 20 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_pickle(fname, data):\n",
    "    with open(f\"../output/{fname}.pickle\", \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "\n",
    "save_pickle(\"roads\", roads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

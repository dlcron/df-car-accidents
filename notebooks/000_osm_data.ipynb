{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cel\n",
    "Wyciągnięcie danych na temat dróg i POI w województwie śląskim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from OSMPythonTools.nominatim import Nominatim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting overpass.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile overpass.py\n",
    "\n",
    "import urllib\n",
    "\n",
    "from OSMPythonTools.overpass import Overpass\n",
    "\n",
    "\n",
    "class CustomOverpass(Overpass):\n",
    "    \n",
    "    # make sure it is GET method with properly (from the point of overpass api server) \n",
    "    # escaped query strings\n",
    "    def _queryRequest(self, endpoint, queryString, params=None):\n",
    "        # is the the overpass server broken?\n",
    "        # qstr = urllib.parse.urlencode({'data': queryString, **(params or {})})\n",
    "        qstr = \"&\".join(f\"{k}={v}\" for k, v in {'data': queryString, **(params or {})}.items())\n",
    "        print( endpoint + f\"interpreter?{qstr}\")\n",
    "        return urllib.request.Request(\n",
    "            endpoint + f\"interpreter?{qstr}\", \n",
    "            method=\"GET\"\n",
    "        )\n",
    "    \n",
    "    # add util method for building sample queries\n",
    "    def from_statements(self, statements, **kwargs):\n",
    "        query = (\n",
    "            \"(\" + \n",
    "            \";\".join(statement for statement in statements) +\n",
    "            \";);\" +\n",
    "            \"out+skel+body+meta+geom;\"\n",
    "        )\n",
    "        \n",
    "        return self.query(query, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from overpass import *\n",
    "nominatim = Nominatim()          \n",
    "overpass = CustomOverpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "silesia = nominatim.query(\"województwo śląskie\", params={\"polygon_geojson\": 1}).toJSON()[0]\n",
    "bbox = silesia[\"boundingbox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.6 s, sys: 19.7 s, total: 1min 7s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get road segments with all possible tags\n",
    "road_segments = overpass.from_statements(\n",
    "    statements = [\n",
    "        \"way[highway](bbox)\",\n",
    "        \"node(w)\",\n",
    "    ],\n",
    "    params={\"bbox\": \",\".join([bbox[2], bbox[0], bbox[3], bbox[1]])},\n",
    "    timeout=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature(element, coords, shape_type, values_to_ignore=None):\n",
    "    values_to_ignore = values_to_ignore or []\n",
    "    tags = {\n",
    "        k: v\n",
    "        for k, v in element.get(\"tags\", {}).items()\n",
    "        if v not in values_to_ignore\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"type\": \"Feature\",\n",
    "        \"id\": f\"{element['type']}/{element['id']}\",\n",
    "        \"properties\": {\n",
    "            \"id\": f\"{element['type']}/{element['id']}\",\n",
    "            **tags\n",
    "        },\n",
    "        \"geometry\": {\n",
    "            \"type\": shape_type,\n",
    "            \"coordinates\": coords\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def transform_to_geojson(overpass_elements, types=None, values_to_ignore=None, **kwargs):\n",
    "    if not types:\n",
    "        types = []\n",
    "    \n",
    "    nodes = [element for element in overpass_elements if element[\"type\"] == \"node\"]\n",
    "    ways = [element for element in overpass_elements if element[\"type\"] == \"way\"]\n",
    "    relations = [element for element in overpass_elements if element[\"type\"] == \"relation\"]\n",
    "    \n",
    "    return {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": (\n",
    "            ([\n",
    "                build_feature(\n",
    "                    element, \n",
    "                    (element[\"lon\"], element[\"lat\"]),\n",
    "                    shape_type=\"Point\",\n",
    "                    values_to_ignore=values_to_ignore\n",
    "                )\n",
    "                for element in nodes if kwargs.get(\"node_condition\", lambda x: x)(element)\n",
    "            ] if \"nodes\" in types else [])\n",
    "            + ([\n",
    "                build_feature(\n",
    "                    element, \n",
    "                    [(node[\"lon\"], node[\"lat\"]) for node in element[\"geometry\"]],\n",
    "                    shape_type=\"LineString\",\n",
    "                    values_to_ignore=values_to_ignore\n",
    "                )\n",
    "                for element in ways            \n",
    "            ] if \"ways\" in types else [])\n",
    "            + ([\n",
    "                build_feature(\n",
    "                    element, \n",
    "                    [\n",
    "                        tuple([\n",
    "                            (point[\"lon\"], point[\"lat\"]) \n",
    "                            for point in node[\"geometry\"]\n",
    "                        ])\n",
    "                        for node in element[\"members\"]\n",
    "                        if node[\"type\"] == \"way\"\n",
    "                    ],\n",
    "                    shape_type=\"MultiLineString\",\n",
    "                    values_to_ignore=values_to_ignore\n",
    "                )\n",
    "                for element in relations \n",
    "            ] if \"relations\" in types else [])\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "178it [00:31,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 6.95 s, total: 27.5 s\n",
      "Wall time: 31.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def batch_entries(collection, batch_size=25000):\n",
    "    ix = 0\n",
    "\n",
    "    while collection[ix * batch_size: (ix + 1) * batch_size ]:\n",
    "        yield collection[ix * batch_size: (ix + 1) * batch_size]\n",
    "        ix += 1\n",
    "\n",
    "\n",
    "ix = 0\n",
    "for collection in tqdm(batch_entries(road_segments.toJSON()[\"elements\"])):\n",
    "    ways_data = transform_to_geojson(\n",
    "        collection, \n",
    "        types=[\"ways\"],\n",
    "        values_to_ignore=[\"2017-09-31\"]\n",
    "    )\n",
    "    if ways_data[\"features\"]:\n",
    "        with open(f\"../output/ways.{ix:04}.geojson\", \"w\") as f:\n",
    "            f.write(json.dumps(ways_data))\n",
    "    \n",
    "    nodes_data = transform_to_geojson(\n",
    "        collection, \n",
    "        types=[\"nodes\"],\n",
    "        node_condition=lambda x: x.get(\"tags\")\n",
    "    )\n",
    "    if nodes_data[\"features\"]:\n",
    "        with open(f\"../output/nodes.{ix:04}.geojson\", \"w\") as f:\n",
    "            f.write(json.dumps(nodes_data))\n",
    "    \n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 11.1 s, total: 24.2 s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "\n",
    "def find_intersections(overpass_elements):\n",
    "    counter = Counter()\n",
    "    nodes = {\n",
    "        element[\"id\"]: (element[\"lat\"], element[\"lon\"])\n",
    "        for element in overpass_elements if element[\"type\"] == \"node\"\n",
    "    }\n",
    "    highways = {\n",
    "        \"motorway\", \n",
    "        \"trunk\",\n",
    "        \"primary\",\n",
    "        \"secondary\",\n",
    "        \"tertiary\",\n",
    "        \"unclassified\",\n",
    "        \"residential\",\n",
    "        \"service\",\n",
    "        \"motorway_link\",\n",
    "        \"trunk_link\",\n",
    "        \"primary_link\",\n",
    "        \"secondary_link\",\n",
    "        \"motorway_junction\"\n",
    "    }\n",
    "    for way in overpass_elements:\n",
    "        if way[\"type\"] == \"way\" and way[\"tags\"][\"highway\"] in highways:\n",
    "            for node in way[\"nodes\"]:\n",
    "                counter[node] += 1\n",
    "\n",
    "    return [nodes[node_id] for (node_id, count) in counter.items() if count > 1]\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_records(\n",
    "    find_intersections(road_segments.toJSON()[\"elements\"]),\n",
    "    columns=(\"lat\", \"lon\")\n",
    ")\n",
    "intersections_gdf = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), \n",
    "    crs=\"epsg:4326\",\n",
    ")\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [05:04<00:00, 11.27s/it]\n",
      "100%|██████████| 152/152 [00:29<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 17s, sys: 7.91 s, total: 5min 25s\n",
      "Wall time: 5min 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shape_gdf = gpd.read_file(json.dumps(silesia))\n",
    "\n",
    "def build_dataframe(pattern):\n",
    "    for file in tqdm(sorted(glob.glob(pattern))):\n",
    "        yield gpd.sjoin(\n",
    "            gpd.read_file(file, crs=\"epsg:4326\"), \n",
    "            shape_gdf, \n",
    "            op=\"within\"\n",
    "        )\n",
    "\n",
    "roads_gdfs = list(build_dataframe(pattern=\"../output/ways*.geojson\"))\n",
    "pois_gdfs = list(build_dataframe(pattern=\"../output/nodes*.geojson\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 29.9 s, total: 2min 9s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "roads = pd.concat(roads_gdfs).replace({None: np.nan})\n",
    "pois = pd.concat(pois_gdfs).replace({None: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 3.95 s, total: 22.7 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_pickle(fname, data):\n",
    "    with open(f\"../output/{fname}.pickle\", \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "\n",
    "def read_pickle(fname):\n",
    "    with open(f\"../input/{fname}.pickle\", \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "save_pickle(\"roads\", roads)\n",
    "save_pickle(\"pois\", pois)\n",
    "save_pickle(\"intersections\", intersections_gdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
